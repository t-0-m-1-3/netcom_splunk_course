# What is Splunk?
----

Splunk is a way to aggregate, analyze, and get answers from *Machine Data*

5 Main functions: 
1. Index Data
2. Search and Ivnestigate
3. Add Knowledge
4. Monitor & Alert
5. Report & Analyze

App management, Operations Management, Security & Compliance, and everything else.
*Single Pane of Glass*

### What's Machine Data?
----
* Machine data is anything that is generated by a device and stored in some form of log.
* 90% of data accumulated by organizations; 
* Structured and unstructured data; 
* can be very hard to process due to this. 
* Big Data types of issues
[![Foo]( https://www.3pillarglobal.com/wp-content/uploads/2016/04/splunk_1.png)]( https://www.3pillarglobal.com/wp-content/uploads/2016/04/splunk_1.png)

## Splunk components
[![Foo](https://docs.splunk.com/images/thumb/e/e0/Horizontal_scaling_new2_60.png/500px-Horizontal_scaling_new2_60.png)](https://docs.splunk.com/images/thumb/e/e0/Horizontal_scaling_new2_60.png/500px-Horizontal_scaling_new2_60.png)
* Splunk Search Head:
    * Allow user to use the Search language
    * Distribute user search requests to indexers
    * consolidates results and extracts field value pairs 
    * *Knowledge Objects* on the search heads can be created to extract new fields or transform the data
    * Provide toolds to enchance the search experience such as reports, dashsboards, and visualizations
* Splunk Indexer:
    * Process machine data stores results indexed as events, enabling fast search and analysis
    * creates a number of file organized in directories by age ( of compressed raw data and pointers to it )
* Splunk Forwarders:
    * Enterprise instances that consume and send data to the index
    * Require minimal resources and have liitle performance overhead
    * Typically reside on machines where data originates
    * Primary way data is supplied
* Deployment Servers:
    * Single Server, testing proof of concept
* Cluseter Masters
    * I can cluster each component
* License Master
     
## How Splunk is Deployed:
 * in the *Enterprise*: installed and adminstered on site
 * in the *Cloud*: Scalable Service with no infrastructure required
 * *Splunk Light*: Small IT Environment
 
## What are Splunk Apps:
* Desinged to address a wide variety of use cases and to extend the power of splunk
* Collections of files containing data inputs, UI elements, and/or knowledge objects
* Allow multiple workspace for different use cases/user roles to co-exist on a single splunk instance
* 1000+ ready-made apps

[![Foo](https://dev.splunk.com/web_assets/developers/devguide/Essentials01_solution.png)](https://dev.splunk.com/web_assets/developers/devguide/Essentials01_solution.png)

## Enhanced Solutions:
IT Service Intel -> monitoring for analytics and OPS
Splunk Enterprise Security -> Comprehensive Securtiy Informtaion and Event Management
Splunk User Behavior Analysis -> finds know and unknown and hidden threats analyzing user behavior

## Users and Roles:
3 main roles: 
    * Admin 
    * Power 
    * User
* roles control everything, admin can create new roles

```
| rest /services/authentication/users | mvexpand roles | table realname, title, roles, email | join roles [ rest /services/authorization/roles | rename title as roles | search srchIndexesAllowed=* | table roles srchIndexesAllowed]
```
[![Foo](https://answers.splunk.com/storage/temp/65294-splunk-user-roles.jpg)](https://answers.splunk.com/storage/temp/65294-splunk-user-roles.jpg)

## Installing Splunk
[![Foo](https://jamey.info/wp-content/uploads/2017/08/splunk.jpg)](https://jamey.info/wp-content/uploads/2017/08/splunk.jpg)

Download the file through the web portal or the `wget -O` CLI tool
 
## Getting data into Splunk
[![Foo](https://cdn-images-1.medium.com/max/1600/1*zeQUCJBPDgShD-5pwINmDA.png)](https://cdn-images-1.medium.com/max/1600/1*zeQUCJBPDgShD-5pwINmDA.png) 

#### *Monitor*, *Upload single Files*, or *Forwarders* 

[![Foo](https://dev.splunk.com/web_assets/developers/devguide/WhatSplunkCanIndex.jpg)](https://answers.splunk.com/storage/temp/110179-62-home.png)
 Pull any data from any source:
  * Computers
  * Network devices
  * VMs
  * Internet devices
  * Com devices
  * sensors
  * databases
  * logs
  * configs
  * messages
  * call detail records
  * clickstream
  * alerts
  * metrics
  * scripts
  * changes
  * tickets
        
## Index time process is really three phases:
* Input Phase: handled at the source
* Parsing Phase: handled by indexers
* Indexing Phase: license meter run, after write, cannot be changed.

[![Foo](https://docs.splunk.com/images/b/b7/Datapipeline_60.png)](https://docs.splunk.com/images/b/b7/Datapipeline_60.png)

## *Data Input Types*:
[![Foo](https://dev.splunk.com/web_assets/developers/addonbuilder/AOB_datainputs1.png)](https://dev.splunk.com/web_assets/developers/addonbuilder/AOB_datainputs1.png)
* *Files and Directories*: monitoring text files and/or dir structures of text files
* *Network Data*: listeing on a port for network data
* *Script Output*:executing a sript andusing the output from it as input
* *Windows Logs*: event logs, Active Directory, etc
* *HTTP*: HTTP Event Collector
* and more
* *Add Data Inputs with*:
    * Splunkbase apps
    * Splunk WEb
    * Cli
    * edit `inputs.conf`
* *Default MetaData Setting*:
    * *Source*: path of input file, network hostname:port, or script name
    * *host*: Splunk hostname of input instance (forwarder)
    * *sourcetype*: source filename if not automatically determined
    * *index*: default of *main*
## Add Input With Splunk Web
* Admins can click the *Add Data* icon and run through the wizard on the *Home* page or the *Settings* panel
     
[![Foo](https://www.learnsplunk.com/uploads/2/7/1/9/2719363/5212201_orig.png)](https://www.learnsplunk.com/uploads/2/7/1/9/2719363/5212201_orig.png)
## The Menu Contains 3 Options:
 * *Upload* allows only uploading of local files that get indexed once. Does not create `inputs.conf` and it never updated. 
 * *Monitor* Proives one-time or continuos monitoring of files, directories, http events, network ports, or data gatehring scripts on Enterprise instances
 * *Forward* Main source of input in production environments, comes from remote machines that gather and pass it along
## Selecting a Source
* The wizard will walk you through the main componenets needed or it to run, allow you to choose *index once* (does not create `inputs.conf`)or *continuously monitor*. You can *Browse* to you file locations as well.
* *Selecting a Source Type* lets you see how splunk will see your data, it allows you to create a new *source type* if you do not see  one that splunk has found. 
* Splunk determins the source type for major data types
* you can choose a different one on the dropdown
* or create your own
* *Data Preview* will show you how the processed events will be indexed. Look for *Proper Separation* and *TimeStamps*
  * Numerous Pretrained sourcetypes
* *Input Settings*:
  * App Context determins where the input settings are saved. 
  * default host name in the *General* settings is used, you can change this here
  * Select the index in which the input should be stored or create a new one ( can lead to large gains in efficeincy )
           
## What does Splunk Do Next:
 * Events are available immediately after they are indexed.
           
## User Interface
[![Foo](https://cdn-images-1.medium.com/max/1600/1*zeQUCJBPDgShD-5pwINmDA.png)](https://cdn-images-1.medium.com/max/1600/1*zeQUCJBPDgShD-5pwINmDA.png) 
* *Home App*
    * Current App
* *Search App*
    * Splunk Bar
    * Current View
    * Search Bar
    * Search History
    * Data Sources
    * Global stats
    * time range picker
    * start search
    * current app
* *Data Summary Tabs*
    * Host -> Unique ID of origin
    * Source -> Name of file, stream, input
    * Sourectype -> specific data type
    * *Event Tab*
        * App
        * Search 
        * Event
        * Field
        * Value
